{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import re\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadr\n",
    "import os\n",
    "#import unidecodeall\n",
    "#import xgboost as xgb\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from joblib import dump, load\n",
    "\n",
    "from spanish_nlp import preprocess\n",
    "from spanish_nlp import augmentation\n",
    "from spanish_nlp.utils.stopwords import extended_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>texto</th>\n",
       "      <th>clase</th>\n",
       "      <th>clase1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>enfermero clinico atencion directas pacientes ...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>enfermera clinica administracion atencion dire...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>profesora ed fisica realizar clases ed fisica ...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>cuidadora niño baña cuida comida niño años</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>vendedores almacen vende compra mercaderia</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69634</th>\n",
       "      <td>1.329554e+11</td>\n",
       "      <td>operador de linea matanza de salmones para aba...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69635</th>\n",
       "      <td>1.329561e+11</td>\n",
       "      <td>assora  de  inversiones asesorias a clientes t...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69636</th>\n",
       "      <td>1.329618e+11</td>\n",
       "      <td>quimico farmacia realiza  fabricacion  de  pro...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69637</th>\n",
       "      <td>1.329638e+11</td>\n",
       "      <td>operario agricola opera  tractor, recogedora  ...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69638</th>\n",
       "      <td>1.329676e+11</td>\n",
       "      <td>pequeño gnado  vacuno cuida sus animales encie...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69639 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text_id                                              texto  clase  \\\n",
       "0      1.000000e+00  enfermero clinico atencion directas pacientes ...   22.0   \n",
       "1      2.000000e+00  enfermera clinica administracion atencion dire...   22.0   \n",
       "2      4.000000e+00  profesora ed fisica realizar clases ed fisica ...   23.0   \n",
       "3      5.000000e+00         cuidadora niño baña cuida comida niño años   53.0   \n",
       "4      7.000000e+00         vendedores almacen vende compra mercaderia   52.0   \n",
       "...             ...                                                ...    ...   \n",
       "69634  1.329554e+11  operador de linea matanza de salmones para aba...   93.0   \n",
       "69635  1.329561e+11  assora  de  inversiones asesorias a clientes t...   33.0   \n",
       "69636  1.329618e+11  quimico farmacia realiza  fabricacion  de  pro...   22.0   \n",
       "69637  1.329638e+11  operario agricola opera  tractor, recogedora  ...   83.0   \n",
       "69638  1.329676e+11  pequeño gnado  vacuno cuida sus animales encie...   61.0   \n",
       "\n",
       "       clase1  \n",
       "0           2  \n",
       "1           2  \n",
       "2           2  \n",
       "3           5  \n",
       "4           5  \n",
       "...       ...  \n",
       "69634       9  \n",
       "69635       3  \n",
       "69636       2  \n",
       "69637       8  \n",
       "69638       6  \n",
       "\n",
       "[69639 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lee archivo csv con variables exógenas\n",
    "ciuo_df = pd.read_csv(\"data_in/ciuo08_v8.csv\",encoding='utf-8', index_col=0)\n",
    "ciuo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b14_glosa</th>\n",
       "      <th>cise</th>\n",
       "      <th>cine</th>\n",
       "      <th>b1_1_rev4</th>\n",
       "      <th>b14_1_rev4cl_caenes</th>\n",
       "      <th>b14_2d</th>\n",
       "      <th>texto</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELABORACION DE JUGOS NATURALES Y SANEWICHEROS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56</td>\n",
       "      <td>ELABORACION DE JUGOS NATURALES Y SANEWICHEROS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELABORACION DE JUGOS NATURALES Y SANDWICHES</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56</td>\n",
       "      <td>ELABORACION DE JUGOS NATURALES Y SANDWICHES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELABORACIOND E JUGOS NATURALES Y SANDWICHES</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56</td>\n",
       "      <td>ELABORACIOND E JUGOS NATURALES Y SANDWICHES</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SERVICIO MANTENCION DE SOLDADURA Y CALDERIA, M...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33</td>\n",
       "      <td>SERVICIO MANTENCION DE SOLDADURA Y CALDERIA, M...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RECTIFICACION DE MOTORES  CAMION DE ALTO TONELAJE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33</td>\n",
       "      <td>RECTIFICACION DE MOTORES  CAMION DE ALTO TONELAJE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184262</th>\n",
       "      <td>ELABORACION DE PAN Y PASTELES</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>ELABORACION DE PAN Y PASTELES</td>\n",
       "      <td>184263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184263</th>\n",
       "      <td>DISTRIBUIDORA Y VENTA DE GAS NATURAL A DOMICILIO</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48</td>\n",
       "      <td>DISTRIBUIDORA Y VENTA DE GAS NATURAL A DOMICILIO</td>\n",
       "      <td>184264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184264</th>\n",
       "      <td>VENTA DE ABARROTES, CONSERVAS, UTILES DE ASEO ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48</td>\n",
       "      <td>VENTA DE ABARROTES, CONSERVAS, UTILES DE ASEO ...</td>\n",
       "      <td>184265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184265</th>\n",
       "      <td>SERVICIOS DE CONSTRUCCION  Y  REPARACION DE VE...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41</td>\n",
       "      <td>SERVICIOS DE CONSTRUCCION  Y  REPARACION DE VE...</td>\n",
       "      <td>184266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184266</th>\n",
       "      <td>CULTIVO  DE  UVAS  A  CAMPO  ABIERTO</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>CULTIVO  DE  UVAS  A  CAMPO  ABIERTO</td>\n",
       "      <td>184267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177781 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                b14_glosa  cise  cine  \\\n",
       "0           ELABORACION DE JUGOS NATURALES Y SANEWICHEROS   1.0   5.0   \n",
       "1             ELABORACION DE JUGOS NATURALES Y SANDWICHES   3.0   5.0   \n",
       "2             ELABORACIOND E JUGOS NATURALES Y SANDWICHES   2.0   6.0   \n",
       "3       SERVICIO MANTENCION DE SOLDADURA Y CALDERIA, M...   3.0   7.0   \n",
       "4       RECTIFICACION DE MOTORES  CAMION DE ALTO TONELAJE   3.0   5.0   \n",
       "...                                                   ...   ...   ...   \n",
       "184262                      ELABORACION DE PAN Y PASTELES   3.0   5.0   \n",
       "184263   DISTRIBUIDORA Y VENTA DE GAS NATURAL A DOMICILIO   3.0   5.0   \n",
       "184264  VENTA DE ABARROTES, CONSERVAS, UTILES DE ASEO ...   3.0   5.0   \n",
       "184265  SERVICIOS DE CONSTRUCCION  Y  REPARACION DE VE...   3.0   4.0   \n",
       "184266               CULTIVO  DE  UVAS  A  CAMPO  ABIERTO   3.0   4.0   \n",
       "\n",
       "        b1_1_rev4  b14_1_rev4cl_caenes  b14_2d  \\\n",
       "0             1.0                  9.0      56   \n",
       "1             3.0                  9.0      56   \n",
       "2             4.0                  9.0      56   \n",
       "3             2.0                  3.0      33   \n",
       "4             3.0                  3.0      33   \n",
       "...           ...                  ...     ...   \n",
       "184262        7.0                  3.0      10   \n",
       "184263        8.0                  7.0      48   \n",
       "184264        9.0                  7.0      48   \n",
       "184265        7.0                  6.0      41   \n",
       "184266        9.0                  1.0       1   \n",
       "\n",
       "                                                    texto      id  \n",
       "0           ELABORACION DE JUGOS NATURALES Y SANEWICHEROS       1  \n",
       "1             ELABORACION DE JUGOS NATURALES Y SANDWICHES       2  \n",
       "2             ELABORACIOND E JUGOS NATURALES Y SANDWICHES       3  \n",
       "3       SERVICIO MANTENCION DE SOLDADURA Y CALDERIA, M...       4  \n",
       "4       RECTIFICACION DE MOTORES  CAMION DE ALTO TONELAJE       5  \n",
       "...                                                   ...     ...  \n",
       "184262                      ELABORACION DE PAN Y PASTELES  184263  \n",
       "184263   DISTRIBUIDORA Y VENTA DE GAS NATURAL A DOMICILIO  184264  \n",
       "184264  VENTA DE ABARROTES, CONSERVAS, UTILES DE ASEO ...  184265  \n",
       "184265  SERVICIOS DE CONSTRUCCION  Y  REPARACION DE VE...  184266  \n",
       "184266               CULTIVO  DE  UVAS  A  CAMPO  ABIERTO  184267  \n",
       "\n",
       "[177781 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caenes_df = pd.read_csv(\"data_in/caenes.csv\",encoding='latin1',index_col=0)\n",
    "caenes_df.dropna(inplace=True)\n",
    "caenes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = preprocess.SpanishPreprocess(\n",
    "        lower=True,\n",
    "        remove_url=False,\n",
    "        remove_hashtags=False,\n",
    "        split_hashtags=False,\n",
    "        normalize_breaklines=True,\n",
    "        remove_emoticons=False,\n",
    "        remove_emojis=False,\n",
    "        convert_emoticons=False,\n",
    "        convert_emojis=False,\n",
    "        normalize_inclusive_language=False,\n",
    "        reduce_spam=False,\n",
    "        remove_reduplications=False,\n",
    "        remove_vowels_accents=False,\n",
    "        remove_multiple_spaces=True,\n",
    "        remove_punctuation=True,\n",
    "        remove_unprintable=False,\n",
    "        remove_numbers=False,\n",
    "        remove_stopwords=True,\n",
    "        stopwords_list='default',\n",
    "        lemmatize=False,\n",
    "        stem=False,\n",
    "        remove_html_tags=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciuo_df['texto'] = ciuo_df['texto'].apply(lambda texto: sp.transform(texto, debug = False))\n",
    "# Obtén la lista de etiquetas únicas\n",
    "labels_unique = ciuo_df['clase'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "caenes_df['texto'] = caenes_df['texto'].apply(lambda texto: sp.transform(texto, debug = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predicted_probabilities, y_test, labels):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['normal', 'odio', 'incivilidad'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end=\"\\t\")\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    f1_macro = round(f1_score(y_test, predicted_labels, average='macro'), 3)\n",
    "    print(\"F1 macro:\", f1_macro)\n",
    "    f1_micro = round(f1_score(y_test, predicted_labels, average='micro'), 3)\n",
    "    print(\"F1 micro:\", f1_micro)\n",
    "    print(\"------------------------------------------------------\\n\")\n",
    "    return np.array([kappa, accuracy, f1_macro, f1_micro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(samples, labels, pipeline, version):\n",
    "    \"\"\"Creamos el pipeline y luego lo ejecutamos el pipeline sobre un dataset.\n",
    "    Retorna el modelo ya entrenado mas sus labels asociadas y los scores obtenidos al evaluarlo.\"\"\"\n",
    "\n",
    "    # Dividimos el dataset en train y test, aún no se transforma de Strings a valores numéricos.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        samples,\n",
    "        labels,\n",
    "        shuffle=True,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    print(f\"# Datos de entrenamiento en dataset: {len(X_train)}\")\n",
    "    print(f\"# Datos de testing en dataset: {len(X_test)}\")\n",
    "\n",
    "    # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline).\n",
    "    # En este caso el Bag of Words es el encargado de transformar de Strings a vectores numéricos.\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    dump(pipeline, 'models/'+version+'.joblib') \n",
    "    # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
    "    predicted_probabilities = pipeline.predict_proba(X_test)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # Obtenemos el orden de las clases aprendidas.\n",
    "    learned_labels = pipeline.classes_\n",
    "\n",
    "    # Evaluamos:\n",
    "    scores = evaluate(predicted_probabilities, y_test, learned_labels)\n",
    "    return pipeline, learned_labels, scores, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_1d():\n",
    "\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"features\",\n",
    "                FeatureUnion( # Acá van las features\n",
    "                    [\n",
    "                        (\"tfidf\", TfidfVectorizer()),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"SVM_sin_esc\", SVC(C=0.75,kernel='linear',probability=True)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_2d():\n",
    "\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"features\",\n",
    "                FeatureUnion( # Acá van las features\n",
    "                    [\n",
    "                        (\"tfidf\", TfidfVectorizer()),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"SVM\", SVC(C=1.0,kernel='linear',probability=True)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Datos de entrenamiento en dataset: 55711\n",
      "# Datos de testing en dataset: 13928\n",
      "Kappa: 0.773\tAccuracy: 0.804\n",
      "F1 macro: 0.717\n",
      "F1 micro: 0.804\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el pipeline\n",
    "pipeline = baseline_1d()\n",
    "\n",
    "# Ejecutamos el pipeline sobre el dataset y guardamos el clasificador, las labels aprendidas y los scores obtenidos\n",
    "classifier_1d, learned_labels_1d, scores_1d, y_test_1d, y_pred_1d = run(ciuo_df.texto, ciuo_df.clase1, pipeline, 'baseline_ciuo1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Datos de entrenamiento en dataset: 55711\n",
      "# Datos de testing en dataset: 13928\n",
      "Kappa: 0.763\tAccuracy: 0.773\n",
      "F1 macro: 0.701\n",
      "F1 micro: 0.773\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el pipeline\n",
    "pipeline = baseline_2d()\n",
    "\n",
    "# Ejecutamos el pipeline sobre el dataset y guardamos el clasificador, las labels aprendidas y los scores obtenidos\n",
    "classifier_2d, learned_labels_2d, scores_2d, y_test_2d, y_pred_2d = run(ciuo_df.texto, ciuo_df.clase, pipeline,'baseline_ciuo2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Datos de entrenamiento en dataset: 142224\n",
      "# Datos de testing en dataset: 35557\n",
      "Kappa: 0.934\tAccuracy: 0.94\n",
      "F1 macro: 0.891\n",
      "F1 micro: 0.94\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el pipeline\n",
    "pipeline = baseline_1d()\t\n",
    "\n",
    "# Ejecutamos el pipeline sobre el dataset y guardamos el clasificador, las labels aprendidas y los scores obtenidos\n",
    "classifier_1d, learned_labels_1d, scores_1d, y_test_1d, y_pred_1d = run(caenes_df.texto, caenes_df.b14_1_rev4cl_caenes, pipeline, 'baseline_caenes1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Datos de entrenamiento en dataset: 142224\n",
      "# Datos de testing en dataset: 35557\n",
      "Kappa: 0.91\tAccuracy: 0.916\n",
      "F1 macro: 0.785\n",
      "F1 micro: 0.916\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos el pipeline\n",
    "pipeline = baseline_2d()\n",
    "\n",
    "# Ejecutamos el pipeline sobre el dataset y guardamos el clasificador, las labels aprendidas y los scores obtenidos\n",
    "classifier_2d, learned_labels_2d, scores_2d, y_test_2d, y_pred_2d = run(caenes_df.texto, caenes_df.b14_2d, pipeline,'baseline_caenes2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidar_clasificaciones(carpeta):\n",
    "    # Obtener la lista de archivos CSV en el directorio\n",
    "    archivos_csv = [archivo for archivo in os.listdir(carpeta) if archivo.endswith('.csv')]\n",
    "\n",
    "    # Verificar si hay archivos CSV en el directorio\n",
    "    if not archivos_csv:\n",
    "        print(\"No se encontraron archivos CSV en el directorio proporcionado.\")\n",
    "        return\n",
    "\n",
    "    # Inicializar un diccionario para almacenar los datos consolidados\n",
    "    datos_consolidados = {}\n",
    "\n",
    "    # Recorrer cada archivo CSV y consolidar los datos\n",
    "    for archivo_csv in archivos_csv:\n",
    "        ruta_archivo = os.path.join(carpeta, archivo_csv)\n",
    "        # Leer el archivo CSV\n",
    "        datos = pd.read_csv(ruta_archivo)\n",
    "        # Iterar sobre cada fila del DataFrame\n",
    "        for indice, fila in datos.iterrows():\n",
    "            id_texto = fila['id']\n",
    "            clase = fila['preds']\n",
    "            probabilidad = fila['probs']\n",
    "            modelo = archivo_csv\n",
    "\n",
    "            # Verificar si el ID de texto ya está en el diccionario\n",
    "            if id_texto in datos_consolidados:\n",
    "                # Verificar si la probabilidad es mayor que la almacenada\n",
    "                if probabilidad > datos_consolidados[id_texto]['prob']:\n",
    "                    # Actualizar los datos consolidados\n",
    "                    datos_consolidados[id_texto] = {'clase': clase, 'prob': probabilidad, 'modelo': modelo}\n",
    "            else:\n",
    "                # Agregar el ID de texto al diccionario\n",
    "                datos_consolidados[id_texto] = {'clase': clase, 'prob': probabilidad, 'modelo': modelo}\n",
    "\n",
    "    # Convertir el diccionario a un DataFrame\n",
    "    df_consolidado = pd.DataFrame.from_dict(datos_consolidados, orient='index').reset_index()\n",
    "    df_consolidado.columns = ['ID', 'clase', 'prob', 'modelo']\n",
    "\n",
    "    # Obtener el nombre del modelo de la ruta\n",
    "    nombre_modelo = os.path.basename(carpeta)\n",
    "\n",
    "    # Guardar el DataFrame consolidado en un archivo CSV\n",
    "    ruta_salida = os.path.join(\"data_out\", f'clasificacion_{nombre_modelo}.csv')\n",
    "    df_consolidado.to_csv(ruta_salida, index=False)\n",
    "    \n",
    "    print(f\"Clasificación consolidada guardada en: {ruta_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación consolidada guardada en: data_out/clasificacion_ciuo1d.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "filepath = Path('data_out/ciuo1d/')\n",
    "consolidar_clasificaciones(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
